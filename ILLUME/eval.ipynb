{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c059d8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2823154798.py, line 106)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 106\u001b[0;36m\u001b[0m\n\u001b[0;31m    elif model_name == \"illume:\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "import json\n",
    "import os\n",
    "from ILLUME.imagenet_hierarchy import direct_subclasses, hierarchy_attr_to_classes, super_class_dir\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "hierarchy_name = 'extended_v1'\n",
    "\n",
    "\n",
    "def compute_acc_and_ent(count_dict, set_dir, q_cluster, q_cls):\n",
    "\n",
    "    top_1_dir = count_dict['top_1']\n",
    "    top_5_dir = count_dict['top_5']\n",
    "\n",
    "    total_count = sum(list(top_1_dir.values()))\n",
    "\n",
    "    pred_prob_dict = {img_cls: float(pred_ct)/total_count for img_cls, pred_ct in top_1_dir.items()}\n",
    "    # print(pred_prob_dict)\n",
    "\n",
    "    # all_leafs = hierarchy_attr_to_classes[hierarchy_name][q_cluster] if q_cluster in hierarchy_attr_to_classes[hierarchy_name] else [q_cluster]\n",
    "    # Uniform distribution (each category has equal probability)\n",
    "    # desired_probs_dict = {leaf: 1.0 / len(all_leafs) for leaf in all_leafs}\n",
    "\n",
    "\n",
    "    # desired_classes_list = list( set( desired_probs_dict.keys()))\n",
    "    # print(desired_classes_list)\n",
    "    # print(f\"top_1 dir: {top_1_dir}\")\n",
    "\n",
    "    all_cluster_classes = hierarchy_attr_to_classes[hierarchy_name][q_cluster] if q_cluster in hierarchy_attr_to_classes[hierarchy_name] else [q_cluster]\n",
    "    count_correct_top_1 = sum([value for key, value in top_1_dir.items() if key in all_cluster_classes])\n",
    "    acc_top_1 = float(count_correct_top_1) / float(total_count)\n",
    "\n",
    "    count_correct_top_5 = sum([value for key, value in top_5_dir.items() if key in all_cluster_classes])\n",
    "    acc_top_5 = float(count_correct_top_5) / float(sum(list(top_5_dir.values())))\n",
    "    print(f\"count_correct_top_1: {count_correct_top_1} ; count_correct_top_5: {count_correct_top_5}\")\n",
    "\n",
    "    # pred_prob_list_filtered = [pred_prob_dict[key] if key in pred_prob_dict else 0.0 for key in all_cluster_classes]\n",
    "    # pred_prob_list = list(pred_prob_dict.values())\n",
    "    \n",
    "    # print(pred_prob_list)\n",
    "    # ent = defaultdict(float)\n",
    "    ent = {}\n",
    "    for super_class in super_class_dir[hierarchy_name][q_cls]:\n",
    "        if super_class == \"animal.n.01\":\n",
    "            continue\n",
    "        all_leafs = hierarchy_attr_to_classes[hierarchy_name][super_class]\n",
    "        pred_prob_list_filtered = [pred_prob_dict[key] if key in pred_prob_dict else 0.0 for key in all_leafs]\n",
    "        ent[super_class] = categorical_entropy(pred_prob_list_filtered)\n",
    "\n",
    "    # print(f\"Entropy is {ent}\")\n",
    "\n",
    "    # desired_prob_list = [desired_probs_dict[key] for key in desired_classes_list]\n",
    "\n",
    "    # Compute KL divergence\n",
    "    # kl_div = scipy.stats.entropy(desired_prob_list, pred_prob_list)  # KL(P || Q)\n",
    "\n",
    "    # cat_ce = categorical_crossentropy(true_dist=desired_prob_list, pred_dist=pred_prob_list)\n",
    "\n",
    "    # print(f\"KL Divergence: {kl_div:.4f}\")\n",
    "    # print(f\"Categorical Cross-Entropy: {kl_div:.4f}\")\n",
    "    return acc_top_1, acc_top_5, ent\n",
    "\n",
    "\n",
    "\n",
    "def categorical_entropy(probs, base=np.e):\n",
    "    probs = np.array(probs)\n",
    "    probs = probs[probs > 0]  # Remove zero probabilities to avoid log(0)\n",
    "    return -np.sum(probs * np.log(probs) / np.log(base))\n",
    "\n",
    "set_direction_attr = \"animal.n.01\"\n",
    "\n",
    "model_name = \"illume\"\n",
    "\n",
    "if model_name == \"Set Learner\":\n",
    "    json_dir = \"/export/scratch/ra48gaq/set_rf_dit/outputs/eval_paper\"\n",
    "elif model_name == \"Visual Prompting v1\":\n",
    "    json_dir = \"/export/scratch/ra48gaq/set_rf_dit/outputs/eval_paper/vis_prompt\"\n",
    "elif model_name == \"Visual Prompting v2\":\n",
    "    json_dir = \"/export/scratch/ra48gaq/set_rf_dit/outputs/eval_paper/vis_prompt_v2\"\n",
    "elif model_name == \"Set Learner Sketch qs\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/ours_sketch_qs\"\n",
    "elif model_name == \"Set Learner Sketch ctx\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/ours_sketch_ctx\"\n",
    "elif model_name == \"Set Learner Sketch both\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/ours_sketch_both\"\n",
    "elif model_name == \"Visual Prompting Sketch qs\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/vis_prompt_sketch_qs\"\n",
    "elif model_name == \"Visual Prompting Sketch ctx\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/vis_prompt_sketch_ctx\"\n",
    "elif model_name == \"Visual Prompting Sketch both\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/vis_prompt_sketch_both\"\n",
    "elif model_name == \"Visual Prompting v3\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/vis_prompt_v3\"\n",
    "elif model_name == \"Ablation FFN\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/ours_ablation_ffn\"\n",
    "elif model_name == \"Ablation 2dirs fixes setsize\":\n",
    "    json_dir = \"/home/hpc/v104dd/v104dd24/code/diffusion/outputs/ours_ablation_2dirs_fix_setsize\"\n",
    "elif model_name == \"Visual Prompting 21k ctx\":\n",
    "    json_dir = \"/anvme/workspace/v104dd11-compvis_data/kolja/set_learner/outputs/vis_prompt_21k_ctx\"\n",
    "elif model_name == \"illume\":\n",
    "    json_dir = \"/export/home/ra48gaq/code/ILLUME_plus/outputs\"\n",
    "else:\n",
    "    print(\"Error: No valid model name provided\")\n",
    "\n",
    "all_animal_classes = list(hierarchy_attr_to_classes[hierarchy_name]['animal.n.01'])\n",
    "\n",
    "acc_list_top_1 = []\n",
    "acc_list_top_5 = []\n",
    "accs_per_set_dir_top_1 = defaultdict(list)\n",
    "accs_per_set_dir_top_5 = defaultdict(list)\n",
    "\n",
    "entropy_ratios = []\n",
    "\n",
    "for animal_class in all_animal_classes:\n",
    "    count_file = os.path.join(json_dir, f\"{animal_class}_predicted_cls_count_per_dir_per_q.json\")\n",
    "    with open(count_file, 'r') as f:\n",
    "        count_dict = json.load(f)\n",
    "    \n",
    "    entropies = {}\n",
    "    for set_direction, count_dict_dir in count_dict.items():\n",
    "        # Compute entropy\n",
    "        # print(count_dict_dir)\n",
    "        # Compute accuracy\n",
    "\n",
    "        super_class_list = super_class_dir[hierarchy_name][animal_class]\n",
    "\n",
    "        # print(f\"set_direction is {set_direction} ; count_file is {count_file}\")\n",
    "\n",
    "        q_sub_cls = list(set(super_class_list) & set(direct_subclasses[hierarchy_name][set_direction]))\n",
    "        # print(f\"q_sub_cls: {q_sub_cls}\")\n",
    "\n",
    "        q_sub_cls = q_sub_cls[0] if len(q_sub_cls) > 0 else animal_class\n",
    "\n",
    "        acc_top_1, acc_top_5, ent = compute_acc_and_ent(count_dict_dir[animal_class], set_dir=set_direction, q_cluster=q_sub_cls, q_cls=animal_class)\n",
    "        print(f\"For query class {animal_class} projected onto {set_direction} direction, top-1 acc for subcluster {q_sub_cls} is {acc_top_1 * 100}% ;  entropy is {ent}\")\n",
    "        acc_list_top_1.append(acc_top_1)\n",
    "        acc_list_top_5.append(acc_top_5)\n",
    "        accs_per_set_dir_top_1[set_direction].append(acc_top_1)\n",
    "        accs_per_set_dir_top_5[set_direction].append(acc_top_5)\n",
    "\n",
    "        entropies[set_direction] = ent\n",
    "\n",
    "    ### Calculate entropy ratios\n",
    "    print(f\"entropy dict for animal class {animal_class} is {entropies}\")\n",
    "    for set_direction in count_dict.keys():\n",
    "        # Compare to next lower set direction,  if there is one\n",
    "        direct_sub = list(set(direct_subclasses[hierarchy_name][set_direction]) & set(count_dict.keys()))\n",
    "        if len(direct_sub) > 0:\n",
    "            direct_sub = direct_sub[0]\n",
    "            print(f\"Comparing entropies for animal class {animal_class} projected onto {set_direction} and {direct_sub}\")\n",
    "            entropy_abstract = entropies[set_direction][direct_sub]\n",
    "            entropy_specific = entropies[direct_sub][direct_sub]\n",
    "            entropy_ratio = entropy_abstract / entropy_specific\n",
    "            print(f\"Entropy ratio is {entropy_ratio}\")\n",
    "            entropy_ratios.append(max(entropy_ratio, 0))\n",
    "\n",
    "# Compute average top 1 acc\n",
    "mean_acc_top_1 = sum(acc_list_top_1) / len(acc_list_top_1)\n",
    "mean_acc_per_set_dir_top_1 = {set_dir: sum(acc_list_per_dir) / len(acc_list_per_dir) for set_dir, acc_list_per_dir in accs_per_set_dir_top_1.items()}\n",
    "# Compute average top 5 acc\n",
    "mean_acc_top_5 = sum(acc_list_top_5) / len(acc_list_top_5)\n",
    "mean_acc_per_set_dir_top_5 = {set_dir: sum(acc_list_per_dir) / len(acc_list_per_dir) for set_dir, acc_list_per_dir in accs_per_set_dir_top_5.items()}\n",
    "# Compute mean entropy ratio\n",
    "mean_ent_ratio = sum(entropy_ratios) / len(entropy_ratios)\n",
    "\n",
    "mean_acc_avg_set_top_1 = sum(mean_acc_per_set_dir_top_1.values()) / len(mean_acc_per_set_dir_top_1)\n",
    "mean_acc_avg_set_top_5 = sum(mean_acc_per_set_dir_top_5.values()) / len(mean_acc_per_set_dir_top_5)\n",
    "print(f\" ===== RESULTS FOR MODEL {model_name} =======\")\n",
    "print(f\" ===== MEAN ACCURACY avg over set-query combinations: TOP-1: {mean_acc_top_1 * 100}% =======\")\n",
    "print(f\" ===== MEAN ACCURACY avg over set directions: TOP-1: {mean_acc_avg_set_top_1 * 100}% =======\")\n",
    "print(f\" ===== MEAN ENTROPY RATIO: {mean_ent_ratio} =======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d63f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (illume)",
   "language": "python",
   "name": "illume"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
